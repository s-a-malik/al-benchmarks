program: cluster_experiment_runner.py
entity: ucl-msc-al-benchmarks
project: al-benchmarks
name: mlp-hyper-tune

method: random    # bayes
metric:
  goal: minimize
  name: acq_model/val_loss

parameters:
  # optim
  batch_size:
    values: [4, 8, 16, 32, 64]
  lr:
    # log uniform requires min and max to be exponential powers i.e. searches between exp(min) and exp(max)
    distribution: log_uniform
    min: -13.8
    max: -2.3
  L2_reg:
    distribution: log_uniform
    min: -13.8
    max: -0.693
  
  # architecture
  hid_dims:
    values:
      - "[16]"
      - "[16, 16]"
      - "[32]"
      - "[32, 32]"
      - "[64]"
      - "[64, 64]"
      - "[128]"
      - "[128, 128]"
      - "[256]"
      - "[256, 256]"
  dropout:
    distribution: uniform
    min: 0.0
    max: 0.8
  fine_tune:
    values: ["true", "false"]

# early_terminate:
#   type: hyperband
#   s: 2
#   eta: 3
#   max_iter: 27

# do not include environment as already given by shell script
command:
  - python3
  - "-u"
  - ${program}
  - "--config"
  - "experiments/hyper-tune-config.yaml"
  - ${args}   # this is all the parameters in the sweep config